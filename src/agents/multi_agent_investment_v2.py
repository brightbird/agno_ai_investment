"""
å¤šAgentä»·å€¼æŠ•èµ„åˆ†æç³»ç»Ÿ V2
åŸºäºå¯é…ç½®æŠ•èµ„Agentç³»ç»Ÿçš„å‡çº§ç‰ˆæœ¬
æ”¯æŒåŠ¨æ€é…ç½®å’Œæ›´å¤šæŠ•èµ„å¤§å¸ˆ
"""

import os
import concurrent.futures
import time
import yaml
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from agno.agent import Agent
from agno.models.openai.like import OpenAILike
from agno.tools.reasoning import ReasoningTools
from .configurable_investment_agent import ConfigurableInvestmentAgent, ConfigurableMultiAgentAnalyzer

# å¯¼å…¥tokenç®¡ç†å·¥å…·
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.token_manager import TokenManager, TokenBudget, StreamingAnalyzer

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def load_default_model_from_config():
    """ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½é»˜è®¤æ¨¡å‹"""
    try:
        current_dir = os.path.dirname(__file__)
        config_file = os.path.join(current_dir, "..", "config", "investment_agents_config.yaml")
        
        with open(config_file, 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
            return config['model_config']['default_model']
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ¨¡å‹ï¼Œä½¿ç”¨fallback: qwen-plusï¼Œé”™è¯¯: {e}")
        return "qwen-plus"

class EnhancedInvestmentSynthesizer:
    """
    å¢å¼ºç‰ˆæŠ•èµ„åˆ†æç»¼åˆå™¨
    æ”¯æŒæ›´å¤šæŠ•èµ„å¤§å¸ˆçš„è§‚ç‚¹ç»¼åˆå’Œtokenä¼˜åŒ–
    """
    def __init__(self, model_id=None, enable_token_optimization=True):
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é»˜è®¤æ¨¡å‹
        if model_id is None:
            model_id = load_default_model_from_config()
            print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ¨¡å‹: {model_id}")
        
        # ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API
        model = OpenAILike(
            id=model_id,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            api_key=os.getenv("ALIYUN_API_KEY")
        )
        
        # åˆå§‹åŒ–tokenç®¡ç†å™¨
        self.token_manager = TokenManager(TokenBudget(
            max_total_tokens=6000,  # é™ä½æ€»tokené™åˆ¶
            max_input_tokens=4500,
            max_output_tokens=1500,
            reserve_tokens=300
        ))
        
        self.enable_token_optimization = enable_token_optimization
        self.streaming_analyzer = StreamingAnalyzer(self.token_manager)
        
        # åˆ›å»ºç»¼åˆåˆ†æAgent
        self.synthesizer = Agent(
            name="å¤šæŠ•èµ„å¤§å¸ˆç»¼åˆåˆ†æå¸ˆ",
            model=model,
            tools=[ReasoningTools(add_instructions=True)],
            instructions=[
                "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„åˆ†æç»¼åˆå¸ˆï¼Œè´Ÿè´£æ•´åˆå¤šä½æŠ•èµ„å¤§å¸ˆçš„è§‚ç‚¹ã€‚",
                "è¯·ç”Ÿæˆç®€æ´ã€ç»“æ„åŒ–çš„æŠ•èµ„åˆ†ææŠ¥å‘Šã€‚",
                "é‡ç‚¹å…³æ³¨å…³é”®ä¿¡æ¯å’Œå¯æ‰§è¡Œçš„æŠ•èµ„å»ºè®®ã€‚",
                "é¿å…é‡å¤å†…å®¹ï¼Œç¡®ä¿åˆ†æç²¾å‡†é«˜æ•ˆã€‚"
            ],
            markdown=True,
            show_tool_calls=False
        )

    def synthesize_analyses(self, analyses_results: List[Dict[str, Any]], mode: str = "auto") -> str:
        """
        ç»¼åˆå¤šä¸ªæŠ•èµ„å¤§å¸ˆçš„åˆ†æç»“æœ
        
        Args:
            analyses_results: å¤šä¸ªæŠ•èµ„å¤§å¸ˆçš„åˆ†æç»“æœåˆ—è¡¨
            mode: å¤„ç†æ¨¡å¼ ("auto", "compressed", "streaming", "full")
            
        Returns:
            ç»¼åˆåˆ†ææŠ¥å‘Š
        """
        if not analyses_results:
            return "âŒ æ²¡æœ‰å¯åˆ†æçš„æ•°æ®"
        
        symbol = analyses_results[0]['symbol'] if analyses_results else "æœªçŸ¥"
        master_count = len(analyses_results)
        
        # ä¼°ç®—è¾“å…¥tokenæ•°
        total_input_tokens = sum(
            self.token_manager.estimate_tokens(str(result)) 
            for result in analyses_results
        )
        
        print(f"ğŸ“Š è¾“å…¥æ•°æ®ä¼°ç®—: {total_input_tokens} tokens")
        
        # æ ¹æ®tokenæ•°é‡è‡ªåŠ¨é€‰æ‹©å¤„ç†æ¨¡å¼
        if mode == "auto":
            if total_input_tokens > self.token_manager.budget.max_input_tokens:
                mode = "compressed"
            elif total_input_tokens > self.token_manager.budget.max_input_tokens * 0.8:
                mode = "streaming"
            else:
                mode = "full"
        
        print(f"ğŸ”„ ä½¿ç”¨å¤„ç†æ¨¡å¼: {mode}")
        
        if mode == "compressed":
            return self._synthesize_compressed(symbol, analyses_results)
        elif mode == "streaming":
            return self._synthesize_streaming(symbol, analyses_results)
        else:
            return self._synthesize_full(symbol, analyses_results)

    def _synthesize_compressed(self, symbol: str, analyses_results: List[Dict[str, Any]]) -> str:
        """å‹ç¼©æ¨¡å¼ç»¼åˆåˆ†æ"""
        print("ğŸ—œï¸ ä½¿ç”¨å‹ç¼©æ¨¡å¼è¿›è¡Œåˆ†æ...")
        
        # å‹ç¼©åˆ†æç»“æœ
        compressed_analyses = self.token_manager.compress_analysis_results(analyses_results)
        
        prompt = f"""
åŸºäº{len(compressed_analyses)}ä½æŠ•èµ„å¤§å¸ˆå¯¹{symbol}çš„åˆ†ææ‘˜è¦ï¼Œç”ŸæˆæŠ•èµ„æŠ¥å‘Šï¼š

{self._format_compressed_analyses(compressed_analyses)}

è¯·è¾“å‡ºç®€æ´çš„ç»“æ„åŒ–æŠ¥å‘Šï¼š

# ğŸ“Š {symbol} æŠ•èµ„åˆ†ææŠ¥å‘Š

## ğŸ¯ æŠ•èµ„å»ºè®®
| é¡¹ç›® | ç»“è®º |
|------|------|
| æ¨èæ“ä½œ | [ä¹°å…¥/æŒæœ‰/å–å‡º] |
| ç»¼åˆè¯„åˆ† | [X/10åˆ†] |
| é£é™©ç­‰çº§ | [ä½/ä¸­/é«˜] |

## ğŸ­ å¤§å¸ˆå…±è¯†
{self._create_consensus_table(compressed_analyses)}

## âš ï¸ å…³é”®é£é™©
- [é£é™©1]
- [é£é™©2]
- [é£é™©3]

## ğŸ’° æ‰§è¡Œå»ºè®®
- **ä¹°å…¥ä»·ä½**: $[ä»·æ ¼åŒºé—´]
- **ç›®æ ‡ä»“ä½**: [X]%
- **æ­¢æŸä½**: $[ä»·æ ¼]

---
*åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M')} | å‚ä¸å¤§å¸ˆ: {len(compressed_analyses)}ä½*
"""
        
        # ä¼˜åŒ–prompt
        optimized_prompt = self.token_manager.optimize_prompt_template(prompt)
        
        print(f"ğŸ” ä¼˜åŒ–åprompté•¿åº¦: {self.token_manager.estimate_tokens(optimized_prompt)} tokens")
        
        response = self.synthesizer.run(optimized_prompt)
        
        # å¤„ç†RunResponseå¯¹è±¡ï¼Œæå–å­—ç¬¦ä¸²å†…å®¹
        if hasattr(response, 'content'):
            analysis_text = response.content
        elif hasattr(response, 'text'):
            analysis_text = response.text
        elif hasattr(response, 'message'):
            analysis_text = response.message
        else:
            # å¦‚æœæ²¡æœ‰è¿™äº›å±æ€§ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            analysis_text = str(response)
            
        return analysis_text

    def _synthesize_streaming(self, symbol: str, analyses_results: List[Dict[str, Any]]) -> str:
        """æµå¼æ¨¡å¼ç»¼åˆåˆ†æ"""
        print("ğŸŒŠ ä½¿ç”¨æµå¼æ¨¡å¼è¿›è¡Œåˆ†æ...")
        
        # ä½¿ç”¨æµå¼åˆ†æå™¨
        streaming_result = self.streaming_analyzer.stream_multi_master_analysis(symbol, analyses_results)
        
        # ç»„åˆå„ä¸ªéƒ¨åˆ†
        sections = streaming_result["sections"]
        
        full_report = f"""
# ğŸ“Š {symbol} ç»¼åˆæŠ•èµ„åˆ†ææŠ¥å‘Š

{sections["executive_summary"]}

{sections["master_opinions"]}

{sections["risk_assessment"]}

{sections["investment_plan"]}

---
*ğŸ“Š åˆ†æå®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
*ğŸ­ å‚ä¸åˆ†æå¤§å¸ˆ: {len(analyses_results)}ä½*
*âš¡ å¤„ç†æ¨¡å¼: æµå¼åˆ†æ*
"""
        return full_report

    def _synthesize_full(self, symbol: str, analyses_results: List[Dict[str, Any]]) -> str:
        """å®Œæ•´æ¨¡å¼ç»¼åˆåˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        print("ğŸ“„ ä½¿ç”¨å®Œæ•´æ¨¡å¼è¿›è¡Œåˆ†æ...")
        
        # ç”Ÿæˆç®€åŒ–çš„å®Œæ•´æŠ¥å‘Š
        prompt = f"""
åŸºäºä»¥ä¸‹{len(analyses_results)}ä½æŠ•èµ„å¤§å¸ˆå¯¹è‚¡ç¥¨{symbol}çš„åˆ†æï¼Œç”Ÿæˆç»¼åˆæŠ•èµ„æŠ¥å‘Šï¼š

{self._format_analyses_summary(analyses_results)}

è¯·ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šï¼ŒåŒ…å«ï¼šæ‰§è¡Œæ‘˜è¦ã€å¤§å¸ˆè§‚ç‚¹å¯¹æ¯”ã€é£é™©è¯„ä¼°ã€æŠ•èµ„è®¡åˆ’
ä¿æŒå†…å®¹ç®€æ´å®ç”¨ï¼Œé¿å…å†—ä½™ä¿¡æ¯ã€‚
"""
        
        # æˆªæ–­promptä»¥ç¡®ä¿ä¸è¶…è¿‡é™åˆ¶
        truncated_prompt = self.token_manager.truncate_text(
            prompt, 
            self.token_manager.budget.max_input_tokens - 500
        )
        
        response = self.synthesizer.run(truncated_prompt)
        
        # å¤„ç†RunResponseå¯¹è±¡ï¼Œæå–å­—ç¬¦ä¸²å†…å®¹
        if hasattr(response, 'content'):
            analysis_text = response.content
        elif hasattr(response, 'text'):
            analysis_text = response.text
        elif hasattr(response, 'message'):
            analysis_text = response.message
        else:
            # å¦‚æœæ²¡æœ‰è¿™äº›å±æ€§ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            analysis_text = str(response)
            
        return analysis_text

    def _format_compressed_analyses(self, compressed_analyses: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å‹ç¼©åçš„åˆ†æç»“æœ"""
        formatted = ""
        for i, analysis in enumerate(compressed_analyses, 1):
            formatted += f"""
### å¤§å¸ˆ{i}: {analysis['agent']}
- å»ºè®®: {analysis['recommendation']}
- æ‘˜è¦: {analysis['summary'][:100]}...
- è¦ç‚¹: {', '.join(analysis['key_points'][:3])}
---
"""
        return formatted

    def _format_analyses_summary(self, analyses_results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœæ‘˜è¦"""
        summaries = []
        for result in analyses_results:
            # æå–å…³é”®ä¿¡æ¯
            agent = result.get('agent', '')
            analysis = result.get('analysis', '')
            
            # æˆªå–åˆ†æçš„å…³é”®éƒ¨åˆ†
            summary = self.token_manager.truncate_text(analysis, 300)
            summaries.append(f"**{agent}**: {summary}")
        
        return "\n\n".join(summaries)

    def _create_consensus_table(self, compressed_analyses: List[Dict[str, Any]]) -> str:
        """åˆ›å»ºå…±è¯†è¡¨æ ¼"""
        rows = []
        for analysis in compressed_analyses:
            master_name = analysis['agent'].split('ä»·å€¼æŠ•èµ„åˆ†æå¸ˆ')[0].strip()
            recommendation = analysis['recommendation']
            summary = analysis['summary'][:30] + "..." if len(analysis['summary']) > 30 else analysis['summary']
            rows.append(f"| {master_name} | {recommendation} | {summary} |")
        
        header = "| æŠ•èµ„å¤§å¸ˆ | å»ºè®® | æ ¸å¿ƒè§‚ç‚¹ |\n|----------|------|----------|"
        return header + "\n" + "\n".join(rows)

class MultiAgentInvestmentAnalyzerV2:
    """
    å¤šAgentæŠ•èµ„åˆ†æç³»ç»Ÿ V2
    é›†æˆtokenä¼˜åŒ–åŠŸèƒ½
    """
    
    def __init__(self, model_id: str = None, enable_token_optimization: bool = True):
        """
        åˆå§‹åŒ–å¤šAgentç³»ç»ŸV2
        
        Args:
            model_id: æ¨¡å‹IDï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤æ¨¡å‹
            enable_token_optimization: æ˜¯å¦å¯ç”¨tokenä¼˜åŒ–
        """
        print("ğŸ¤– åˆå§‹åŒ–å¤šAgentæŠ•èµ„åˆ†æç³»ç»Ÿ V2...")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é»˜è®¤æ¨¡å‹
        if model_id is None:
            model_id = load_default_model_from_config()
            print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ¨¡å‹: {model_id}")
        
        self.enable_token_optimization = enable_token_optimization
        
        # åˆ›å»ºé…ç½®åŒ–å¤šAgentåˆ†æå™¨
        self.config_analyzer = ConfigurableMultiAgentAnalyzer()
        
        # åˆ›å»ºå¢å¼ºç‰ˆç»¼åˆåˆ†æå™¨
        self.synthesizer = EnhancedInvestmentSynthesizer(model_id, enable_token_optimization)
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„æŠ•èµ„å¤§å¸ˆ
        self.available_masters = self.config_analyzer.agent_factory.get_available_masters()
        
        # åˆå§‹åŒ–tokenç®¡ç†å™¨
        if enable_token_optimization:
            self.token_manager = TokenManager()
            print("âœ… Tokenä¼˜åŒ–åŠŸèƒ½å·²å¯ç”¨")
        else:
            self.token_manager = None
        
        print("âœ… å¤šAgentç³»ç»ŸV2åˆå§‹åŒ–å®Œæˆï¼")
        print(f"ğŸ“‹ æ”¯æŒçš„æŠ•èµ„å¤§å¸ˆ: {', '.join(self.available_masters)}")

    def analyze_stock_multi_master(self, 
                                   symbol: str, 
                                   selected_masters: Optional[List[str]] = None,
                                   parallel: bool = True,
                                   show_reasoning: bool = False,
                                   analysis_mode: str = "auto") -> Dict[str, Any]:
        """
        ä½¿ç”¨å¤šä½æŠ•èµ„å¤§å¸ˆåˆ†æè‚¡ç¥¨ï¼ˆæ”¯æŒtokenä¼˜åŒ–ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            selected_masters: é€‰æ‹©çš„æŠ•èµ„å¤§å¸ˆåˆ—è¡¨
            parallel: æ˜¯å¦å¹¶è¡Œåˆ†æ
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            analysis_mode: åˆ†ææ¨¡å¼ ("auto", "compressed", "streaming", "full")
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # Tokenä¼˜åŒ–ï¼šé™åˆ¶å¤§å¸ˆæ•°é‡
        if self.enable_token_optimization and selected_masters:
            if len(selected_masters) > 5:
                print(f"âš ï¸ Tokenä¼˜åŒ–ï¼šé™åˆ¶åˆ†æå¤§å¸ˆæ•°é‡ä»{len(selected_masters)}ä½å‡å°‘åˆ°5ä½")
                selected_masters = selected_masters[:5]
        
        # é€‰æ‹©æŠ•èµ„å¤§å¸ˆ
        if selected_masters is None:
            selected_masters = self.available_masters
            if self.enable_token_optimization:
                selected_masters = selected_masters[:5]  # é™åˆ¶åˆ°5ä½å¤§å¸ˆ
        else:
            # éªŒè¯é€‰æ‹©çš„æŠ•èµ„å¤§å¸ˆ
            invalid_masters = [m for m in selected_masters if m not in self.available_masters]
            if invalid_masters:
                raise ValueError(f"æ— æ•ˆçš„æŠ•èµ„å¤§å¸ˆ: {invalid_masters}")
        
        print(f"\nğŸ¯ å¼€å§‹å¤šæŠ•èµ„å¤§å¸ˆåˆ†æè‚¡ç¥¨: {symbol}")
        print(f"ğŸ’¡ é€‰æ‹©çš„æŠ•èµ„å¤§å¸ˆ: {', '.join(selected_masters)}")
        if self.enable_token_optimization:
            print(f"ğŸ—œï¸ Tokenä¼˜åŒ–æ¨¡å¼: {analysis_mode}")
        print("=" * 80)
        
        start_time = time.time()
        
        # åŠ è½½é€‰æ‹©çš„Agent
        self.config_analyzer.load_agents(selected_masters)
        
        # è¿›è¡Œå¤šè§†è§’åˆ†æ
        multi_analysis_result = self.config_analyzer.analyze_stock_multi_perspective(
            symbol, 
            show_reasoning=show_reasoning
        )
        
        analysis_time = time.time() - start_time
        
        # Tokenä¼˜åŒ–çš„ç»¼åˆåˆ†æ
        print(f"\n{'='*80}")
        print("ğŸ“‹ æ­£åœ¨ç”Ÿæˆç»¼åˆæŠ•èµ„æŠ¥å‘Š...")
        synthesis_result = self.synthesizer.synthesize_analyses(
            multi_analysis_result['individual_analyses'],
            mode=analysis_mode
        )
        
        # æ¸…æ™°åœ°æ˜¾ç¤ºåˆ†æç»“æœ
        print(f"\n{'='*80}")
        print("ğŸ“Š ç»¼åˆæŠ•èµ„åˆ†ææŠ¥å‘Š")
        print("="*80)
        print(synthesis_result)
        
        synthesis_time = time.time() - start_time - analysis_time
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        print(f"\nâ±ï¸  åˆ†æå®Œæˆ!")
        print(f"   ğŸ“Š åˆ†ææ—¶é—´: {analysis_time:.1f}ç§’")
        print(f"   ğŸ”„ ç»¼åˆæ—¶é—´: {synthesis_time:.1f}ç§’")
        print(f"   âš¡ æ€»ç”¨æ—¶: {time.time() - start_time:.1f}ç§’")
        print(f"   ğŸ­ å‚ä¸å¤§å¸ˆ: {len(selected_masters)}ä½")
        if self.enable_token_optimization:
            print(f"   ğŸ—œï¸ ä¼˜åŒ–æ¨¡å¼: {analysis_mode}")
        
        return {
            "symbol": symbol,
            "selected_masters": selected_masters,
            "individual_analyses": multi_analysis_result['individual_analyses'],
            "synthesis": synthesis_result,
            "analysis_mode": analysis_mode,
            "performance": {
                "analysis_time": analysis_time,
                "synthesis_time": synthesis_time,
                "total_time": time.time() - start_time,
                "masters_count": len(selected_masters),
                "token_optimization": self.enable_token_optimization
            }
        }

    def compare_stocks_multi_master(self, 
                                    symbols: List[str],
                                    selected_masters: Optional[List[str]] = None,
                                    show_reasoning: bool = False,
                                    batch_size: int = 3) -> Dict[str, Any]:
        """
        ä½¿ç”¨å¤šä½æŠ•èµ„å¤§å¸ˆæ¯”è¾ƒå¤šåªè‚¡ç¥¨ï¼ˆæ”¯æŒæ‰¹å¤„ç†ï¼‰
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            selected_masters: é€‰æ‹©çš„æŠ•èµ„å¤§å¸ˆåˆ—è¡¨
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            å¯¹æ¯”åˆ†æç»“æœ
        """
        # Tokenä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†è‚¡ç¥¨
        if self.enable_token_optimization and len(symbols) > batch_size:
            print(f"ğŸ”„ Tokenä¼˜åŒ–ï¼šå°†{len(symbols)}åªè‚¡ç¥¨åˆ†{batch_size}åªä¸€æ‰¹è¿›è¡Œå¤„ç†")
            
            # åˆ†æ‰¹å¤„ç†
            stock_batches = self.token_manager.create_batched_analysis(symbols, batch_size)
            all_results = {}
            
            for i, batch in enumerate(stock_batches, 1):
                print(f"\nğŸ“Š å¤„ç†ç¬¬{i}æ‰¹è‚¡ç¥¨: {', '.join(batch)}")
                
                for symbol in batch:
                    result = self.analyze_stock_multi_master(
                        symbol=symbol,
                        selected_masters=selected_masters,
                        parallel=True,
                        show_reasoning=show_reasoning,
                        analysis_mode="compressed"  # æ‰¹å¤„ç†æ—¶ä½¿ç”¨å‹ç¼©æ¨¡å¼
                    )
                    all_results[symbol] = result
                
                if i < len(stock_batches):
                    print("â¸ï¸ æ‰¹æ¬¡é—´æš‚åœ2ç§’...")
                    time.sleep(2)
        else:
            # å¸¸è§„å¤„ç†
            all_results = {}
            for symbol in symbols:
                result = self.analyze_stock_multi_master(
                    symbol=symbol,
                    selected_masters=selected_masters,
                    parallel=True,
                    show_reasoning=show_reasoning
                )
                all_results[symbol] = result
        
        # ç”Ÿæˆç®€åŒ–çš„å¯¹æ¯”æŠ¥å‘Š
        comparison_report = self._generate_simplified_comparison_report(all_results)
        print(f"\n{'='*80}")
        print("ğŸ“ˆ å¤šè‚¡ç¥¨å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        print("="*80)
        print(comparison_report)
        
        return {
            "symbols": symbols,
            "selected_masters": selected_masters,
            "individual_stock_analyses": all_results,
            "comparison_report": comparison_report,
            "batch_processing": self.enable_token_optimization and len(symbols) > batch_size
        }

    def _generate_simplified_comparison_report(self, all_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€åŒ–ç‰ˆå¯¹æ¯”æŠ¥å‘Š"""
        symbols = list(all_results.keys())
        
        # æå–å…³é”®ä¿¡æ¯
        summary_data = []
        for symbol, result in all_results.items():
            summary_data.append({
                "symbol": symbol,
                "masters_count": result["performance"]["masters_count"],
                "total_time": result["performance"]["total_time"]
            })
        
        report = f"""
# ğŸ“Š è‚¡ç¥¨å¯¹æ¯”åˆ†ææŠ¥å‘Š

## ğŸ¯ åˆ†ææ¦‚å†µ
- **å¯¹æ¯”è‚¡ç¥¨**: {', '.join(symbols)}
- **å‚ä¸å¤§å¸ˆ**: {summary_data[0]['masters_count']}ä½
- **æ€»åˆ†ææ—¶é—´**: {sum(item['total_time'] for item in summary_data):.1f}ç§’

## ğŸ“ˆ æŠ•èµ„æ’å
| æ’å | è‚¡ç¥¨ | æ¨èåº¦ | å¤‡æ³¨ |
|------|------|--------|------|
{self._create_ranking_rows(all_results)}

## ğŸ’¡ æŠ•èµ„å»ºè®®
åŸºäºå¤šä½æŠ•èµ„å¤§å¸ˆçš„åˆ†æï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æ’åé å‰çš„è‚¡ç¥¨ã€‚
å…·ä½“æŠ•èµ„å†³ç­–è¯·å‚è€ƒå„è‚¡ç¥¨çš„è¯¦ç»†åˆ†ææŠ¥å‘Šã€‚

---
*âš¡ ç®€åŒ–æŠ¥å‘Šæ¨¡å¼ | ğŸ“Š åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M')}*
"""
        return report

    def _create_ranking_rows(self, all_results: Dict[str, Any]) -> str:
        """åˆ›å»ºæ’åè¡¨æ ¼è¡Œ"""
        rows = []
        for i, (symbol, result) in enumerate(all_results.items(), 1):
            rows.append(f"| {i} | {symbol} | å¾…è¯„ä¼° | è¯¦è§ä¸ªè‚¡åˆ†æ |")
        return "\n".join(rows)

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¤šAgentæŠ•èµ„åˆ†æç³»ç»ŸV2"""
    print("ğŸ¯ å¤šAgentä»·å€¼æŠ•èµ„åˆ†æç³»ç»Ÿ V2")
    print("ğŸ’« æ”¯æŒ5ä½æŠ•èµ„å¤§å¸ˆçš„å¤šè§†è§’æ™ºæ…§åˆ†æ")
    print("ğŸ”§ åŸºäºå¯é…ç½®Agentç³»ç»Ÿçš„å‡çº§ç‰ˆæœ¬")
    print("=" * 80)
    
    # åˆ›å»ºå¤šAgentåˆ†æå™¨V2
    analyzer = MultiAgentInvestmentAnalyzerV2()
    
    while True:
        print(f"\nğŸ“‹ è¯·é€‰æ‹©åˆ†æç±»å‹:")
        print("1. å¤šæŠ•èµ„å¤§å¸ˆå•è‚¡åˆ†æ")
        print("2. å¤šæŠ•èµ„å¤§å¸ˆå¤šè‚¡å¯¹æ¯”")
        print("3. æŸ¥çœ‹æŠ•èµ„å¤§å¸ˆä¿¡æ¯")
        print("4. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if choice == "1":
            # é€‰æ‹©æŠ•èµ„å¤§å¸ˆ
            selected_masters = analyzer.get_master_selection_menu()
            
            # è¾“å…¥è‚¡ç¥¨ä»£ç 
            symbol = input("\nè¯·è¾“å…¥è‚¡ç¥¨ä»£ç  (å¦‚ AAPL): ").strip().upper()
            if symbol:
                analyzer.analyze_stock_multi_master(
                    symbol=symbol,
                    selected_masters=selected_masters,
                    parallel=True,
                    show_reasoning=False
                )
        
        elif choice == "2":
            # é€‰æ‹©æŠ•èµ„å¤§å¸ˆ
            selected_masters = analyzer.get_master_selection_menu()
            
            # è¾“å…¥è‚¡ç¥¨ä»£ç 
            symbols_input = input("\nè¯·è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œç”¨é€—å·åˆ†éš” (å¦‚ AAPL,MSFT,GOOGL): ").strip().upper()
            if symbols_input:
                symbols = [s.strip() for s in symbols_input.split(",")]
                analyzer.compare_stocks_multi_master(
                    symbols=symbols,
                    selected_masters=selected_masters,
                    show_reasoning=False
                )
        
        elif choice == "3":
            analyzer.config_analyzer.get_master_comparison()
        
        elif choice == "4":
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¤šAgentæŠ•èµ„åˆ†æç³»ç»ŸV2ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main() 